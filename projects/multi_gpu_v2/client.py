import base64
import requests
import os
from loguru import logger
import asyncio
import aiohttp

def mineru_parse_sync(file_path: str, server_url: str = 'http://127.0.0.1:8000/predict', **options):
    """åŒæ­¥è°ƒç”¨MinerUæœåŠ¡ç«¯é¢„æµ‹æ¥å£ã€‚

    Args:
        file_path: å¾…å¤„ç†æ–‡ä»¶è·¯å¾„
        server_url: æœåŠ¡ç«¯ /predict æ¥å£URL
        **options: é€ä¼ ç»™æœåŠ¡ç«¯çš„å‚æ•°ï¼ŒåŒ…å« backend/method/lang/formula_enable/table_enable/start_page_id/end_page_id/server_url/output_dir ç­‰

    Returns:
        dict: æˆåŠŸè¿”å› { 'output_dir': str }ï¼Œå¤±è´¥è¿”å› { 'error': str }
    """
    try:
        with open(file_path, 'rb') as f:
            file_b64 = base64.b64encode(f.read()).decode('utf-8')

        payload = {
            'file': file_b64,
            'options': options
        }

        resp = requests.post(server_url, json=payload, timeout=300)
        if resp.status_code == 200:
            return resp.json()
        else:
            return {'error': resp.text}
    except Exception as e:
        logger.error(f"åŒæ­¥è°ƒç”¨å¤±è´¥ {file_path}: {e}")
        return {'error': str(e)}

async def mineru_parse_async(session, file_path, server_url='http://10.10.50.52:8111/predict', **options):
    """
    Asynchronous version of the parse function.
    """
    try:
        # Asynchronously read and encode the file
        with open(file_path, 'rb') as f:
            file_b64 = base64.b64encode(f.read()).decode('utf-8')

        payload = {
            'file': file_b64,
            'options': options
        }

        # Use the aiohttp session to send the request with timeout
        timeout = aiohttp.ClientTimeout(total=600)  # 10åˆ†é’Ÿè¶…æ—¶
        async with session.post(server_url, json=payload, timeout=timeout) as response:
            if response.status == 200:
                result = await response.json()
                logger.info(f"âœ… Processed: {file_path} -> {result.get('output_dir', 'N/A')}")
                return result
            else:
                error_text = await response.text()
                logger.error(f"âŒ Server error for {file_path}: {error_text}")
                return {'error': error_text}

    except Exception as e:
        logger.error(f"âŒ Failed to process {file_path}: {e}")
        return {'error': str(e)}

async def mineru_parse_by_file_path(session, file_path, server_url='http://10.10.50.52:8111/predict', **options):
    """
    ä½¿ç”¨æ–‡ä»¶è·¯å¾„æ¨¡å¼è°ƒç”¨MinerUæœåŠ¡ç«¯ï¼Œé¿å…åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    
    Args:
        session: aiohttp session
        file_path: æœåŠ¡ç«¯æœ¬åœ°æ–‡ä»¶è·¯å¾„
        server_url: æœåŠ¡ç«¯URL
        **options: å…¶ä»–é€‰é¡¹å‚æ•°
    """
    try:
        payload = {
            'file_path': file_path,  # ç›´æ¥ä¼ é€’æ–‡ä»¶è·¯å¾„
            'options': options
        }

        # ä½¿ç”¨aiohttp sessionå‘é€è¯·æ±‚ï¼Œè®¾ç½®è¶…æ—¶
        timeout = aiohttp.ClientTimeout(total=600)  # 10åˆ†é’Ÿè¶…æ—¶
        async with session.post(server_url, json=payload, timeout=timeout) as response:
            if response.status == 200:
                result = await response.json()
                logger.info(f"âœ… Processed (file_path mode): {file_path} -> {result.get('output_dir', 'N/A')}")
                return result
            else:
                error_text = await response.text()
                logger.error(f"âŒ Server error for {file_path}: {error_text}")
                return {'error': error_text}

    except Exception as e:
        logger.error(f"âŒ Failed to process {file_path}: {e}")
        return {'error': str(e)}


async def main():
    """
    Main function to run all parsing tasks concurrently.
    æ¼”ç¤ºä¸¤ç§æ¨¡å¼ï¼šæ–‡ä»¶å†…å®¹æ¨¡å¼å’Œæ–‡ä»¶è·¯å¾„æ¨¡å¼
    """
    test_files = [
        '../../demo/pdfs/demo1.pdf',
        '../../demo/pdfs/demo2.pdf',
        '../../demo/pdfs/demo3.pdf',
        '../../demo/pdfs/small_ocr.pdf',
    ]

    test_files = [os.path.join(os.path.dirname(__file__), f) for f in test_files]
    
    existing_files = [f for f in test_files if os.path.exists(f)]
    if not existing_files:
        logger.warning("No test files found.")
        return

    # Create an aiohttp session to be reused across requests
    async with aiohttp.ClientSession() as session:
        # logger.info("=== æ¨¡å¼1ï¼šæ–‡ä»¶å†…å®¹æ¨¡å¼ï¼ˆä¸Šä¼ æ–‡ä»¶å†…å®¹åˆ°æœåŠ¡ç«¯ï¼‰ ===")
        # # === Basic Processing ===
        # basic_tasks = [mineru_parse_async(session, file_path) for file_path in existing_files[:2]]

        # # === Custom Options ===
        # custom_options = {
        #     'backend': 'pipeline', 'lang': 'ch', 'method': 'auto',
        #     'formula_enable': True, 'table_enable': True,'output_dir': './output'
        # }
        # # 'backend': 'sglang-engine' requires 24+ GB VRAM per worker

        # custom_tasks = [mineru_parse_async(session, file_path, **custom_options) for file_path in existing_files[2:]]

        # # Start all tasks
        # all_tasks = basic_tasks + custom_tasks
        # all_results = await asyncio.gather(*all_tasks)
        # logger.info(f"æ–‡ä»¶å†…å®¹æ¨¡å¼ç»“æœ: {all_results}")

        logger.info("\n=== æ¨¡å¼2ï¼šæ–‡ä»¶è·¯å¾„æ¨¡å¼ï¼ˆç›´æ¥ä½¿ç”¨æœåŠ¡ç«¯æœ¬åœ°æ–‡ä»¶ï¼‰ ===")
        # æ–‡ä»¶è·¯å¾„æ¨¡å¼æµ‹è¯• - ä½¿ç”¨æœåŠ¡ç«¯æœ¬åœ°æ–‡ä»¶è·¯å¾„
        server_file_paths = [
            # è¿™äº›è·¯å¾„åº”è¯¥æ˜¯æœåŠ¡ç«¯å¯ä»¥è®¿é—®çš„æ–‡ä»¶è·¯å¾„
            # å¯ä»¥æ˜¯ç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹äºæœåŠ¡ç«¯å·¥ä½œç›®å½•çš„è·¯å¾„
            os.path.abspath(existing_files[0]),  # ä½¿ç”¨ç»å¯¹è·¯å¾„
            os.path.abspath(existing_files[1]) if len(existing_files) > 1 else None,
        ]
        
        server_file_paths = [p for p in server_file_paths if p is not None]
        
        file_path_options = {
            'backend': 'pipeline', 'lang': 'ch', 'method': 'auto',
            'formula_enable': True, 'table_enable': True,
            'output_dir': './output_file'  # ä¸åŒçš„è¾“å‡ºç›®å½•
        }
        
        file_path_tasks = [mineru_parse_by_file_path(session, file_path, **file_path_options) for file_path in server_file_paths]
        file_path_results = await asyncio.gather(*file_path_tasks)
        logger.info(f"æ–‡ä»¶è·¯å¾„æ¨¡å¼ç»“æœ: {file_path_results}")
        
    logger.info("ğŸ‰ All processing completed!")

if __name__ == '__main__':
    # Run the async main function
    asyncio.run(main())
